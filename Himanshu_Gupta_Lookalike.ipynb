{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pTuu_hQVvzE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customers = pd.read_csv(\"Customers.csv\")\n",
        "products = pd.read_csv(\"Products.csv\")\n",
        "transactions = pd.read_csv(\"Transactions.csv\")"
      ],
      "metadata": {
        "id": "8NBuDe8WWYCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
        "transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])"
      ],
      "metadata": {
        "id": "J9v5GSzpWawg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "\n",
        "# Function to normalize features\n",
        "def normalize_features(customer_features):\n",
        "    logging.info(\"=\" * 15 + \" Normalizing feature data \" + \"=\" * 15)\n",
        "\n",
        "    # Select numeric columns\n",
        "    numerical_cols = customer_features.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "    # Normalize only numeric columns\n",
        "    scaler = StandardScaler()\n",
        "    normalized_features = pd.DataFrame(\n",
        "        scaler.fit_transform(customer_features[numerical_cols]),\n",
        "        columns=numerical_cols\n",
        "    )\n",
        "\n",
        "    # Retain non-numeric columns without modification\n",
        "    for col in customer_features.columns:\n",
        "        if col not in numerical_cols:\n",
        "            normalized_features[col] = customer_features[col].values\n",
        "\n",
        "    return normalized_features\n",
        "\n",
        "\n",
        "# Function to calculate similarity and find lookalikes\n",
        "def calculate_lookalikes(customers, transactions, products):\n",
        "    logging.info(\"=\" * 15 + \" Calculating Lookalikes \" + \"=\" * 15)\n",
        "\n",
        "    # Merge datasets to include transaction and product details\n",
        "    merged_data = pd.merge(transactions, customers, on='CustomerID', how='left')\n",
        "    merged_data = pd.merge(merged_data, products, on='ProductID', how='left')\n",
        "\n",
        "    # Aggregate data to get customer-level features\n",
        "    customer_features = merged_data.groupby('CustomerID').agg({\n",
        "        'Quantity': 'sum',  # Total quantity purchased\n",
        "        'TotalValue': 'sum',  # Total value of transactions\n",
        "        'Price_y': 'mean',  # Average product price\n",
        "    }).reset_index()\n",
        "\n",
        "    # Normalize the features (exclude CustomerID)\n",
        "    customer_features_normalized = normalize_features(customer_features.drop(columns=['CustomerID']))\n",
        "\n",
        "    # Compute similarity using cosine similarity (exclude CustomerID column)\n",
        "    similarity_matrix = cosine_similarity(customer_features_normalized)\n",
        "\n",
        "    # Find top 3 similar customers for each customer\n",
        "    lookalikes = {}\n",
        "    for idx, customer_id in enumerate(customer_features['CustomerID']):\n",
        "        similarity_scores = list(enumerate(similarity_matrix[idx]))\n",
        "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "        top_3 = similarity_scores[1:4]  # Exclude the customer itself\n",
        "\n",
        "        lookalikes[customer_id] = [\n",
        "            {'CustomerID': customer_features.iloc[sim[0]]['CustomerID'], 'Score': round(sim[1], 3)}\n",
        "            for sim in top_3\n",
        "        ]\n",
        "\n",
        "    return lookalikes\n",
        "\n",
        "\n",
        "# Function to generate Lookalike.csv\n",
        "def generate_lookalike_csv(lookalikes, output_file=\"Lookalike.csv\"):\n",
        "    logging.info(\"=\" * 15 + \" Generating Lookalike.csv \" + \"=\" * 15)\n",
        "\n",
        "    lookalike_data = []\n",
        "    for customer_id, similar_customers in lookalikes.items():\n",
        "        for similar in similar_customers:\n",
        "            lookalike_data.append({\n",
        "                'CustomerID': customer_id,\n",
        "                'SimilarCustomerID': similar['CustomerID'],\n",
        "                'Score': similar['Score']\n",
        "            })\n",
        "\n",
        "    lookalike_df = pd.DataFrame(lookalike_data)\n",
        "    lookalike_df.to_csv(output_file, index=False)\n",
        "    logging.info(f\"Lookalike.csv generated successfully at {output_file}\")\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Load the datasets\n",
        "    logging.info(\"=\" * 15 + \" Loading Data \" + \"=\" * 15)\n",
        "    customers = pd.read_csv('Customers.csv')\n",
        "    products = pd.read_csv('Products.csv')\n",
        "    transactions = pd.read_csv('Transactions.csv')\n",
        "\n",
        "    # Calculate lookalikes\n",
        "    lookalikes = calculate_lookalikes(customers, transactions, products)\n",
        "\n",
        "    # Generate Lookalike.csv\n",
        "    generate_lookalike_csv(lookalikes)\n",
        "\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Z0EwSAzecDj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}